{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal, Uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LowDimLinearRep():\n",
    "    def __init__(self, input_d, feature_d, output_d, n_source_tasks, n1, n2):\n",
    "        self.input_d = input_d\n",
    "        self.feature_d = feature_d\n",
    "        self.output_d = output_d\n",
    "        self.n_source_tasks = n_source_tasks\n",
    "        self.n1 = n1\n",
    "        self.n2 = n2\n",
    "\n",
    "    def low_dim_check(self):\n",
    "        assert self.feature_d < self.input_d, \"feature dimension should be less than input dimension\"\n",
    "\n",
    "    def representation(self, x):\n",
    "        \"\"\"\n",
    "        maps input x to a low-dimensional representation of dim self.feature_d\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def prediction(self, phi):\n",
    "        \"\"\"\n",
    "        linear prediction of the representation of x\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulation():\n",
    "    def __init__(self, input_d, feature_d):\n",
    "        pass\n",
    "\n",
    "    def generate_data(self, n, rho):\n",
    "        \"\"\"\n",
    "        generate n samples of data\n",
    "        rho^2-subgaussian\n",
    "        following assumption 4.1\n",
    "        \"\"\"\n",
    "        d = self.input_d\n",
    "        vec = torch.normal(0, rho, size=(d,1))\n",
    "        # generate d independent subgaussian random variables to form a subgaussian vector\n",
    "        pass\n",
    "\n",
    "    def representation(self, x):\n",
    "        \"\"\"\n",
    "        ground truth representation function\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def prediction(self, phi):\n",
    "        \"\"\"\n",
    "        ground truth prediction function\n",
    "        \n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def specialization_t(self, A3=True, A4=True, target_task=False):\n",
    "        \"\"\"\n",
    "        generate a specialization function for task t\n",
    "        for assumption 4.3\n",
    "        iid sample from N(0, Sigma) where (max eigenvalue of Sigma)/(min eigenvalue of Sigma) = O(1)\n",
    "\n",
    "        returns w_t, maximun and minimum eigenvalues of Sigma\n",
    "        \"\"\"\n",
    "        k = self.feature_d\n",
    "        if A3:\n",
    "            ev = np.linspace(1.0, 10.0, k)\n",
    "        else:\n",
    "            ev = np.linspace(1.0, 10.0*k, k)\n",
    "        \n",
    "        if A4 and target_task:\n",
    "            ev /= k\n",
    "        \n",
    "        mean = torch.zeros(k)\n",
    "        cov = torch.diag(torch.tensor(ev.astype(np.float32)))\n",
    "\n",
    "        p_t = MultivariateNormal(mean, covariance_matrix=cov)\n",
    "        w_t = p_t.sample()\n",
    "\n",
    "        ev_max = np.max(ev)\n",
    "        ev_min = np.min(ev)\n",
    "        return w_t, ev_max, ev_min\n",
    "\n",
    "    def noise(self, sigma, n):\n",
    "        \"\"\"\n",
    "        simulate gaussian noise vector of length n\n",
    "        \"\"\"\n",
    "        return np.random.normal(0, sigma, n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
